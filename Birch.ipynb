{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d83d8da-1014-4d44-b275-0f8121705dec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import joblib\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from utils import load_and_describe_raw_data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.metrics import accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bedbc0d-d2bf-4351-b47f-a3ef5d5d1555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download ('wordnet')\n",
    "class ProcessData:\n",
    "    def __init__(self,dataset):\n",
    "        self.dataframe = dataset\n",
    "\n",
    "    def eliminate_labels(self):\n",
    "        # Label, not label num\n",
    "        self.dataframe.drop(columns = ['Id','Score','ViewCount','LabelNum'])\n",
    "\n",
    "    def clean_text_and_tokenize(self,text):\n",
    "        text = re.sub(r'[|\\'|\"|#|:|-|&|;|%|“|”]','',text)\n",
    "        text = re.sub(r'[?|!|.|,|)|(|\\\\|\\/]',' ',text)\n",
    "        pattern = re.compile('<[^>]*>|\\'|\\(|\\)|\\\"|”|“|\\?|\\.|,|:|;|&|[|]|-|\\\\\\\\')\n",
    "        text = text.lower()\n",
    "        text = re.sub(pattern, \"\", text)\n",
    "        text = re.sub('[0-9]+', '', text)\n",
    "        text = nltk.word_tokenize(text)\n",
    "        stop_words = stopwords.words('english')\n",
    "        text = [word for word in text if word not in stop_words]\n",
    "       \n",
    "        lemma = WordNetLemmatizer()\n",
    "        text = ' '.join(lemma.lemmatize(word) for word in text)\n",
    "       \n",
    "        return text\n",
    "\n",
    "    def merge_text_labels(self):\n",
    "        self.dataframe['Content'] = self.dataframe['Title'] + self.dataframe['Body']\n",
    "        self.dataframe['Content'] = self.dataframe['Content'].apply(self.clean_text_and_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f504573a-054a-4079-8959-b4a771d0252e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data and process \n",
    "print(\"Loading data...\")\n",
    "X_train,X_valid,X_test = load_and_describe_raw_data()\n",
    "dataset_train = ProcessData(X_train)\n",
    "dataset_train.eliminate_labels()\n",
    "dataset_train.merge_text_labels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91def979-a8f9-426c-8fc1-c456f4dea9a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model class that has basic functions defined\n",
    "class BirchModel:\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.model = None\n",
    "\n",
    "\n",
    "    def tfidf(self):\n",
    "        vectorizer = TfidfVectorizer(min_df=0.025,stop_words='english',max_features=60000)\n",
    "        X = vectorizer.fit_transform(self.data)\n",
    "        \n",
    "        # Get features\n",
    "        #print(vectorizer.get_feature_names_out())\n",
    "        return X\n",
    "\n",
    "    def cluster(self):\n",
    "        self.model = Birch(n_clusters=2,threshold=0.1,branching_factor=25)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c3aaa-94e8-47b6-aaa6-63f95a2b0739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B = BirchModel(dataset_train.dataframe['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b66a105-cfa6-4148-a570-fefe5ed463cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tf-idf feature\n",
    "X = B.tfidf()\n",
    "# Get model\n",
    "B_mod = B.cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2d4681-3d44-4dae-875f-52fb9c09a2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Reduce components\n",
    "pca = PCA(n_components=4)\n",
    "X_pca = pca.fit_transform(X.toarray())\n",
    "X = X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59525271-ccf8-4150-935e-eb8870479e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(\"Fitting the model...\")\n",
    "B_mod.fit(X)\n",
    "labels = B_mod.predict(X)\n",
    "dataset_train.dataframe['y'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128e233d-de41-4e32-8bbf-ac377206def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score:\")\n",
    "print(silhouette_score(X,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1c0a4-bc23-47ae-9fa7-68513e169c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise clusters\n",
    "plt.scatter(X[:,0], X[:,1],c=labels)\n",
    "plt.show()\n",
    "\n",
    "accuracy= accuracy_score(dataset_train.dataframe['LabelNum'], labels)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8b58e-1804-46c6-a4d9-4f34e8a07bf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "dataset_test = ProcessData(X_valid)\n",
    "dataset_test.eliminate_labels()\n",
    "dataset_test.merge_text_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad5f7ca-7f3b-41c6-9beb-cbe8897ba6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B_test = BirchModel(dataset_test.dataframe['Content'])\n",
    "test_data = B_test.tfidf()\n",
    "# pca_test = PCA(n_components=5)\n",
    "test_pca = pca.fit_transform(test_data.toarray())\n",
    "Y = test_pca\n",
    "labels_test = B_mod.predict(Y)\n",
    "accuracy= accuracy_score(dataset_test.dataframe['LabelNum'], labels_test)\n",
    "dataset_test.dataframe['y'] = labels\n",
    "print (accuracy)\n",
    "score = f1_score(dataset_test.dataframe['LabelNum'], labels_test, average=\"macro\")\n",
    "print(score)\n",
    "# for i in X_test.index:\n",
    "#     print(dataset_test.dataframe.iloc[i]['LabelNum'], dataset_test.dataframe.iloc[i]['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5166b4-a9d3-4f92-aed8-17778b0ad141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2vec feature\n",
    "\n",
    "sentences_tokenized = []\n",
    "\n",
    "#tokenize sentence\n",
    "for sentence in dataset_train.dataframe['Content'].values:\n",
    "    sentences_tokenized.append(simple_preprocess(sentence))\n",
    "\n",
    "w2v_model = Word2Vec(sentences_tokenized, workers=4,window=10,)\n",
    "\n",
    "sent_vectors = [];  \n",
    "for sentence in sentences_tokenized:  \n",
    "    sentence_v = np.zeros(100)  \n",
    "    wc = 0; \n",
    "    for word in sentence:  \n",
    "        try:\n",
    "            # add weigths\n",
    "            vec = w2v_model.wv[word]\n",
    "            sentence_v += vec\n",
    "            wc += 1\n",
    "        except:\n",
    "            pass\n",
    "    # average the vectors\n",
    "    sentence_v /= wc\n",
    "    sent_vectors.append(sentence_v)\n",
    "\n",
    "sent_vectors = np.array(sent_vectors)\n",
    "sent_vectors = np.nan_to_num(sent_vectors)\n",
    "\n",
    "B_mod = B.cluster()\n",
    "B_mod.fit(sent_vectors)\n",
    "labels = B_mod.predict(sent_vectors)\n",
    "\n",
    "dataset_train.dataframe['y'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956a7ba6-b628-45b7-9192-e4e1ce7a2dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(silhouette_score(sent_vectors,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3c531-5018-4867-aa00-3e169086cf01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(sent_vectors[:, 0], sent_vectors[:, 1], c=labels, cmap='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8025f5e-963c-47eb-97e4-735ebee339bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hypertuning\n",
    "\n",
    "branching_factor= [25,50,100,150]\n",
    "n_clusters = [2,5,7]\n",
    "threshold = [0.1,0.2,0.5]\n",
    "model_results = {\n",
    "                 'branching_factor': [],\n",
    "                 'n_clusters': [],\n",
    "                 'threshold': [],\n",
    "                 'score': []\n",
    "                }\n",
    "\n",
    "for b in branching_factor:\n",
    "    for cluster in n_clusters:\n",
    "        for t in threshold:\n",
    "            try:\n",
    "                B_mod = Birch(n_clusters=cluster,threshold=t,branching_factor=b)\n",
    "                B_mod.fit(X)\n",
    "                labels = B_mod.predict(X)\n",
    "                score = silhouette_score(X,labels)\n",
    "                model_results['branching_factor'].append(b)\n",
    "                model_results['n_clusters'].append(cluster)\n",
    "                model_results['threshold'].append(t)\n",
    "                model_results['score'].append(score)\n",
    "                print(score)\n",
    "            except:\n",
    "                pass\n",
    "pd.DataFrame(model_results).to_csv('./results/birch_tuning_tfidf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fc691c-d999-462f-98c0-aa4a7f3c81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "sentences_tokenized = []\n",
    "for sentence in dataset_test.dataframe['Content'].values:\n",
    "    sentences_tokenized.append(sentence)\n",
    "\n",
    "#w2v_model = Word2Vec(sentences_tokenized, workers=4)\n",
    "\n",
    "sent_vectors = [];  # the avg-w2v for each sentence/review is stored in this train\n",
    "for sent in sentences_tokenized:  # for each review/sentence\n",
    "    sent_vec = np.zeros(100)  # as word vectors are of zero length\n",
    "    cnt_words = 0;  # num of words with a valid vector in the sentence/review\n",
    "    for word in sent:  # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    sent_vectors.append(sent_vec)\n",
    "\n",
    "sent_vectors = np.array(sent_vectors)\n",
    "sent_vectors = np.nan_to_num(sent_vectors)\n",
    "\n",
    "labels_test = B_mod.predict(sent_vectors)\n",
    "dataset_test.dataframe['y'] = labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2f908e-d9d5-4019-9b02-c5b789d35ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sent_vectors[:, 0], sent_vectors[:, 1], c=labels_test, cmap='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b7ebbb-4eef-4236-b073-f5e5e8edac39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting parameters\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./results/birch_tuning_tfidf.csv')\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.scatter(df['branching_factor'], df['score'])\n",
    "plt.xlabel('Number of branches')\n",
    "plt.ylabel('Score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3ba79d-a431-4a34-91fb-f6e643f7c04a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
